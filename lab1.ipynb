{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourglass Network\n",
    "## For keypoints extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from hourglass import HourglassNetwork\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"YCB-Video_data/data/0010\"\n",
    "IMAGES = [f\"{IMAGES_PATH}/{f}\" for f in os.listdir(IMAGES_PATH) if f.endswith(\"color.png\")]\n",
    "DIM = (480, 640, 3)\n",
    "N = len(IMAGES)\n",
    "\n",
    "KEYPOINTS_PATH = \"YCB-Video_data/keypoints/0010_gt_keypoints2d.npy\"\n",
    "KEYPOINTS = np.load(KEYPOINTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keypoints to heatmaps finctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_k(x0: int, y0: int, sigma: float, height: int, width: int) -> np.ndarray:\n",
    "        \"\"\" Make a square gaussian kernel centered at (x0, y0) with sigma as SD. \"\"\"\n",
    "        x = np.arange(0, width, 1, float) ## (width,)\n",
    "        y = np.arange(0, height, 1, float)[:, np.newaxis] ## (height,1)\n",
    "        return np.exp(-((x-x0)**2 + (y-y0)**2) / (2*sigma**2))\n",
    "\n",
    "def generate_heatmap(height: int, width: int, landmarks: list[tuple[int, int]], s: int = 3) -> np.ndarray:\n",
    "        \"\"\" Generate a full Heap Map for every landmarks in an array\n",
    "        Args:\n",
    "            height    : The height of Heat Map (the height of target output)\n",
    "            width     : The width  of Heat Map (the width of target output)\n",
    "            joints    : [(x1,y1),(x2,y2)...] containing landmarks\n",
    "            maxlenght : Lenght of the Bounding Box\n",
    "        \"\"\"\n",
    "        Nlandmarks = len(landmarks)\n",
    "        hm = np.zeros((height, width, Nlandmarks), dtype = np.float32)\n",
    "        for i in range(Nlandmarks):\n",
    "            if not np.array_equal(landmarks[i], [-1,-1]):\n",
    "             \n",
    "                hm[:,:,i] = gaussian_k(landmarks[i][0],\n",
    "                                        landmarks[i][1],\n",
    "                                        s,height, width)\n",
    "            else:\n",
    "                hm[:,:,i] = np.zeros((height,width))\n",
    "        return hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchgen(images: list[str], keypoints: np.ndarray, dataset_size: int, batch_size: int, epochs: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    for _ in range(epochs):\n",
    "        for i in range(0, dataset_size, batch_size):\n",
    "            x_batch = np.array([cv2.imread(img) for img in images[i:i+batch_size]])\n",
    "            y_batch = np.array([generate_heatmap(DIM[0]//4, DIM[1]//4, k//4) for k in keypoints[i:i+batch_size]])\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hourglass neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "num_stacks = 4\n",
    "num_filters = 32\n",
    "\n",
    "net = HourglassNetwork(num_classes, num_stacks,\n",
    "                       num_filters, DIM, (120, 160))\n",
    "# net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 30\n",
    "net.fit(data_generator=batchgen(IMAGES, KEYPOINTS, dataset_size=N, batch_size=batch_size, epochs=epochs),\n",
    "        dataset_size=N,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_heatmap(img: np.ndarray, heatmap: np.ndarray) -> np.ndarray:\n",
    "    _heatmap = heatmap.sum(axis=-1) # sum all heatmaps\n",
    "    _heatmap = cv2.normalize(_heatmap, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    _heatmap = cv2.resize(_heatmap, (640, 480))  # resize\n",
    "    _heatmap = cv2.applyColorMap(_heatmap, cv2.COLORMAP_JET)\n",
    "    return cv2.addWeighted(_heatmap, .7, img, .3, 0)\n",
    "\n",
    "\n",
    "gen = batchgen(IMAGES, KEYPOINTS, dataset_size=N, batch_size=1, epochs=1)\n",
    "x, y = next(gen)\n",
    "out = net.predict(x)\n",
    "overlay = overlay_heatmap(x[0], out[0])\n",
    "cv2.imshow(\"Heatmap overlay\", overlay)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dea41a0b5387599001cc6b5b190e2b3fe587c5cfd372c1b28b23eb867c4ea1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
